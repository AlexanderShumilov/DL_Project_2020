{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Simpsons.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yKpK4M0H242Y",
        "colab": {}
      },
      "source": [
        "# imports\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import math\n",
        "import random\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from skimage import io\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v5sJ3S-9EtY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# device\n",
        "\n",
        "device = 'cuda:0'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRLHRRcbGVCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset is on the drive, so we should mount it here\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvJp8FtmG58y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/drive/My Drive/Project DL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBYDkU6eHQiG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5hiH471FTks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if you have dataset in zip archive, this should create proper directories\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/My Drive/Project DL/simpsons/simpsons.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/drive/My Drive/Project DL/simpsons/simpsons')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCa7ySI19Kiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# path to images\n",
        "\n",
        "train_dir = Path('/content/drive/My Drive/Project DL/simpsons/simpsons/simpsons_dataset/')\n",
        "test_dir = Path('/content/drive/My Drive/Project DL/simpsons/simpsons/kaggle_simpson_testset/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd3WQFIKAGoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class to help \n",
        "\n",
        "class SimpsonTrainValPath():\n",
        "    \n",
        "  def __init__(self, train_dir, test_dir):\n",
        "    \n",
        "    self.train_dir = train_dir\n",
        "    self.test_dir = test_dir\n",
        "    self.train_val_files_path = sorted(list(self.train_dir.rglob('*.jpg')))\n",
        "    self.test_path = sorted(list(self.test_dir.rglob('*.jpg')))\n",
        "    self.train_val_labels = [path.parent.name for path in self.train_val_files_path]\n",
        "\n",
        "  def get_path(self):\n",
        "      \n",
        "    train_files_path, val_files_path = train_test_split(self.train_val_files_path, test_size = 0.3, \\\n",
        "                                          stratify=self.train_val_labels)\n",
        "    \n",
        "    files_path = {'train': train_files_path, 'val': val_files_path}\n",
        "    \n",
        "    return files_path, self.test_path\n",
        "  \n",
        "  def get_n_classes(self):\n",
        "    return len(np.unique(self.train_val_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlqBFuuEAGlt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get number of classes and paths to images\n",
        "\n",
        "SimpsonTrainValPath = SimpsonTrainValPath(train_dir, test_dir)\n",
        "train_path, test_path = SimpsonTrainValPath.get_path()\n",
        "n_classes = SimpsonTrainValPath.get_n_classes()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NJJRMEQCSZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# should be 42\n",
        "\n",
        "n_classes "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftEeF80e9SSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train loop in function\n",
        "\n",
        "def train_model(model, dataloaders, criterion, optimizer, save_best_weights_path, save_last_weights_path, best_acc, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "    val_loss_history = []\n",
        "    train_acc_history = []\n",
        "    train_loss_history = []\n",
        "    lr_find_lr = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  \n",
        "            else:\n",
        "                model.eval()   \n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in tqdm(dataloaders[phase]):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    if is_inception and phase == 'train':\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                        scheduler.step()\n",
        "                        lr_step = optimizer_ft.state_dict()[\"param_groups\"][0][\"lr\"]\n",
        "                        lr_find_lr.append(lr_step)\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            \n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "                val_loss_history.append(epoch_loss)\n",
        "            else:\n",
        "                train_acc_history.append(epoch_acc)\n",
        "                train_loss_history.append(epoch_loss)\n",
        "        \n",
        "        print()\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    history_val = {'loss': val_loss_history, 'acc': val_acc_history}\n",
        "    history_train = {'loss': train_loss_history, 'acc': train_acc_history}\n",
        "    \n",
        "    return model, history_val, history_train, time_elapsed, lr_find_lr, best_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaWpsrFv9Xdw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for faster validation\n",
        "\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSi6wHmH9Zno",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize parameters of input model\n",
        "\n",
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    \n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "       \n",
        "    if model_name == \"resnet152\":\n",
        "        model_ft = models.resnet152(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224 \n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llTN3AvU9cwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Simpsons dataset\n",
        "\n",
        "class SimpsonsDataset(Dataset):\n",
        "\n",
        "    def __init__(self, files_path, data_transforms):\n",
        "      self.files_path = files_path\n",
        "      self.transform = data_transforms\n",
        "      \n",
        "      if 'test' not in str(self.files_path[0]):\n",
        "        self.labels = [path.parent.name for path in self.files_path]\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.label_encoder.fit(self.labels)\n",
        "        \n",
        "        with open('label_encoder.pkl', 'wb') as le_dump_file:\n",
        "            pickle.dump(self.label_encoder, le_dump_file)\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.files_path)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "      img_path = str(self.files_path[idx]) \n",
        "      image = Image.open(img_path)\n",
        "      image = self.transform(image)\n",
        "      \n",
        "      if 'test' in str(self.files_path[0]):\n",
        "        return image\n",
        "      else: \n",
        "        label_str = str(self.files_path[idx].parent.name)\n",
        "        label = self.label_encoder.transform([label_str]).item()\n",
        "        \n",
        "        return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0YYNIET9e2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# also init of everything\n",
        "\n",
        "model_name = 'resnet152'\n",
        "\n",
        "fc_layer = 'all-st-SGD-m.9-nest-s-cycle-exp-.00001-.05-g.99994-m.8-.9'\n",
        "\n",
        "num_classes = n_classes\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "num_epochs = 2\n",
        "\n",
        "feature_extract = False\n",
        "\n",
        "save_last_weights_path = '/kaggle/working/' + model_name + '-' + fc_layer + '_last_weights.pth'\n",
        "save_best_weights_path = '/kaggle/working/' + model_name + '-' + fc_layer + '_best_weights.pth'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7DgdGXXQ-LW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "model_ft = model_ft.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQnOZCQ-DQxQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VysFvGwC_FX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH_W = '/content/drive/My Drive/Project DL/sympsons.pth'\n",
        "model_ft.load_state_dict(torch.load(PATH_W)) # path to weights "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9WhHUBD9oDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.RandomChoice( [ \n",
        "                                  transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                  transforms.ColorJitter(contrast=0.9),\n",
        "                                  transforms.ColorJitter(brightness=0.1),\n",
        "                                  transforms.RandomApply( [ transforms.RandomHorizontalFlip(p=1), transforms.ColorJitter(contrast=0.9) ], p=0.5),\n",
        "                                  transforms.RandomApply( [ transforms.RandomHorizontalFlip(p=1), transforms.ColorJitter(brightness=0.1) ], p=0.5),\n",
        "                                  ] ),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqhuQhZR9skv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_datasets = {mode: SimpsonsDataset(train_path[mode], data_transforms[mode]) for mode in ['train', 'val']}\n",
        "image_datasets_test = SimpsonsDataset(test_path, data_transforms['val'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWt_KxrG9tIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataloaders_dict = {'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True, num_workers=4),\n",
        "                    'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=True, num_workers=4)}\n",
        "dataloader_test = torch.utils.data.DataLoader(image_datasets_test, batch_size=batch_size, shuffle=False, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjwlfMuG9tLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(inp, title=None, plt_ax=plt, default=False):\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt_ax.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt_ax.set_title(title)\n",
        "    plt_ax.grid(False)\n",
        "    plt_ax.figure.savefig('simpsons_dataset.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWsc-clB9tN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(8, 8), \\\n",
        "                        sharey=True, sharex=True)\n",
        "for fig_x in ax.flatten():\n",
        "    random_characters = int(np.random.uniform(0, 4500))\n",
        "    im_val, label = image_datasets['train'][random_characters]\n",
        "\n",
        "    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
        "                image_datasets['val'].label_encoder.inverse_transform([label])[0].split('_')))\n",
        "    imshow(im_val.data.cpu(), \\\n",
        "          title=img_label,plt_ax=fig_x)\n",
        "    \n",
        "    im = imshow(im_val.data.cpu(), \\\n",
        "          title=img_label,plt_ax=fig_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCr5Dvf49tSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualization(train, val, is_loss = True):\n",
        "  \n",
        "  if is_loss:\n",
        "    plt.figure(figsize=(17,10))\n",
        "    plt.plot(train, label = 'Training loss')\n",
        "    plt.plot(val, label = 'Val loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "  \n",
        "  else:\n",
        "    plt.figure(figsize=(17,10))\n",
        "    plt.plot(train, label = 'Training acc')\n",
        "    plt.plot(val, label = 'Val acc')\n",
        "    plt.title('Training and validation acc')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Acc')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnmKS20b-BDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_lr = 0.0012\n",
        "max_lr = 0.0022\n",
        "num_epoch = 4\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "params_to_update = model_ft.parameters()\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9, nesterov = True)\n",
        "step_size = 2 * math.ceil( len(dataloaders_dict['train']) / batch_size )\n",
        "scheduler = optim.lr_scheduler.CyclicLR(optimizer_ft, base_lr = base_lr, max_lr = max_lr, step_size_up=step_size, mode='exp_range', gamma=0.994, scale_mode='cycle', cycle_momentum=True, base_momentum=0.8, max_momentum=0.9, last_epoch=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sydy8HAE-A-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_loss = []\n",
        "val_acc = []\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "lr_cycle = []\n",
        "best_acc = .0\n",
        "\n",
        "for i in range(num_epoch):\n",
        "      image_datasets = {mode: SimpsonsDataset(train_path[mode], data_transforms[mode]) for mode in ['train', 'val']}\n",
        "\n",
        "    dataloaders_dict = {'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=False, num_workers=4),\n",
        "                          'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=False, num_workers=4)}\n",
        "\n",
        "    model, history_val, history_train, time_elapsed, lr_find_lr, best_acc = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, save_best_weights_path, save_last_weights_path, best_acc = best_acc, num_epochs=1, is_inception=(model_name==\"inception\"))\n",
        "\n",
        "    val_loss += history_val['loss']\n",
        "    val_acc += history_val['acc']\n",
        "    train_loss += history_train['loss']\n",
        "    train_acc += history_train['acc']\n",
        "    lr_cycle += lr_find_lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7ABK_oR-LXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualization(train_acc, val_acc, is_loss = False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo8Fj6QU-LaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualization(train_loss, val_loss, is_loss = True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGmvRRsD-Ld6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, test_loader):\n",
        "    with torch.no_grad():\n",
        "        logits = []\n",
        "    \n",
        "        for inputs in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            model.eval()\n",
        "            outputs = model(inputs).cpu()\n",
        "            logits.append(outputs)\n",
        "            \n",
        "    probs = nn.functional.softmax(torch.cat(logits), dim=1).numpy()\n",
        "    return probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNKJaRKI-Qnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_one_sample(model, img_tensor, device=device):\n",
        "    with torch.no_grad():\n",
        "        img_tensor = img_tensor.to(device)\n",
        "        model.eval()\n",
        "        y_hat = model(img_tensor).cpu()\n",
        "        y_pred = torch.nn.functional.softmax(y_hat, dim=1).numpy()\n",
        "    return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFpPigF8-Qw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def confusion_matrix():\n",
        "    actual = [image_datasets['val'][i][1] for i in range( len(image_datasets['val']) ) ]\n",
        "    \n",
        "    image = [image_datasets['val'][i][0] for i in range( len(image_datasets['val']) ) ]\n",
        "    \n",
        "    img_conf_dataloader = torch.utils.data.DataLoader(image, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "    \n",
        "    probs = predict(model_ft, img_conf_dataloader)\n",
        "    preds = np.argmax(probs, axis=1)\n",
        "    \n",
        "    df = pd.DataFrame({'actual': actual, 'preds': preds})\n",
        "    \n",
        "    confusion_matrix = pd.crosstab(df['actual'], df['preds'], rownames=['Actual'], colnames=['Predicted'], margins = False)\n",
        "    \n",
        "    label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))\n",
        "    \n",
        "    yticklabels = label_encoder.classes_\n",
        "    \n",
        "    plt.subplots(figsize=(20,20))\n",
        "\n",
        "    sn.heatmap(confusion_matrix, annot=True, fmt=\"d\", linewidths=0.5, cmap=\"YlGnBu\", cbar=False, vmax = 30, yticklabels = yticklabels, xticklabels = yticklabels);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Otekx7H-Quq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "confusion_matrix()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXS6B2HN-Qsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.patches as patches\n",
        "from matplotlib.font_manager import FontProperties\n",
        "\n",
        "fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(12, 12), \\\n",
        "                        sharey=True, sharex=True)\n",
        "\n",
        "label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))\n",
        "\n",
        "for fig_x in ax.flatten():\n",
        "    random_characters = int(np.random.uniform(0, 1000))\n",
        "    im_val, label = image_datasets['val'][random_characters]\n",
        "\n",
        "    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
        "                image_datasets['val'].label_encoder.inverse_transform([label])[0].split('_')))\n",
        "    \n",
        "    imshow(im_val.data.cpu(), \\\n",
        "          title=img_label, plt_ax=fig_x)\n",
        "    \n",
        "    actual_text = \"Actual : {}\".format(img_label)\n",
        "\n",
        "    fig_x.add_patch(patches.Rectangle((0, 53), 86, 35, color='white'))\n",
        "    font0 = FontProperties()\n",
        "    font = font0.copy()\n",
        "    font.set_family(\"fantasy\")\n",
        "    prob_pred = predict_one_sample(model_ft, im_val.unsqueeze(0))\n",
        "    # получаем вероятность\n",
        "    predicted_proba = np.max(prob_pred)*100\n",
        "    y_pred = np.argmax(prob_pred)\n",
        "    \n",
        "    predicted_label = label_encoder.classes_[y_pred]\n",
        "    predicted_label = predicted_label[:len(predicted_label)//2] + '\\n' + predicted_label[len(predicted_label)//2:]\n",
        "    predicted_text = \"{} : {:.0f}%\".format(predicted_label,predicted_proba)\n",
        "            \n",
        "    fig_x.text(1, 59, predicted_text , horizontalalignment='left', fontproperties=font,\n",
        "                    verticalalignment='top',fontsize=8, color='black',fontweight='bold')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VRjEcCXeIm_",
        "colab_type": "text"
      },
      "source": [
        "Evaluation of adversarial attack on simpsons dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4eP8eVg-Qqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "class LinfPGDAttack():\n",
        "    def __init__(self, model2, epsilon, num_steps, step_size):#, random_start):\n",
        "        \"\"\"Attack parameter initialization. The attack performs k steps of\n",
        "        size a, while always staying within epsilon from the initial\n",
        "        point.\"\"\"\n",
        "        #self.model1 = make_model()\n",
        "        #self.model1.load_state_dict(torch.load('/content/drive/My Drive/Project_DL/regular_classif_dict.pth', map_location=device))\n",
        "        #self.model1.to(device)\n",
        "        self.epsilon = epsilon\n",
        "        self.num_steps = num_steps\n",
        "        self.step_size = step_size\n",
        "        #self.rand = random_start\n",
        "        self.loss = nn.NLLLoss()\n",
        "\n",
        "    def perturb(self, x_nat, y, labels, model1):\n",
        "        \"\"\"Given a set of examples (x_nat, y), returns a set of adversarial\n",
        "        examples within epsilon of x_nat in l_infinity norm.\"\"\"\n",
        "\n",
        "        e = torch.tensor(np.random.uniform(-self.epsilon, self.epsilon, x_nat.shape)) # ensure valid pixel range     \n",
        "        x_gpu = x_nat.to(device)\n",
        "    \n",
        "        #model1.eval()\n",
        "        t = torch.randint(0, 42, (1,)).to(device)\n",
        "\n",
        "        for i in range(self.num_steps):\n",
        "\n",
        "            x_gpu.requires_grad=True\n",
        "            o = model1(x_gpu)\n",
        "            loss = nn.NLLLoss()(o, t)\n",
        "            grad=torch.autograd.grad(loss, x_gpu,retain_graph=True)\n",
        "\n",
        "            x_gpu.requires_grad=False\n",
        "            x = x_gpu.clone().detach().cpu().numpy()\n",
        "            x = np.add(x, -self.step_size* np.sign(grad[0].detach().cpu().numpy()), casting='unsafe')\n",
        "            x = np.clip(x, x_nat.detach().cpu().numpy() - self.epsilon, x_nat.detach().cpu().numpy() + self.epsilon)\n",
        "            x = np.clip(x, 0, 255)\n",
        "            x_gpu = torch.tensor(x).float().to(device)\n",
        "\n",
        "        return x_gpu, t\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P92zX7ZJElw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHDomaXknBqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_adversarial(model_ft, eps=0.01, num_steps=10, step_size=0.01, plot=False):\n",
        "    attack = LinfPGDAttack(model_ft, eps, num_steps, step_size)\n",
        "    labels = list(range(1, 43))\n",
        "\n",
        "    rand_idx = np.random.randint(len(image_datasets['train']))\n",
        "    x, y = image_datasets['train'][rand_idx]\n",
        "\n",
        "    x=x.reshape(1,3,224,224)\n",
        "    X, t = attack.perturb(x, y, labels, model_ft)\n",
        "    pic_np = X.detach().cpu().numpy().reshape(3, 224,224)\n",
        "    pic_np = np.rollaxis(pic_np, 0, 3)    # 3xHxW to HxWx3\n",
        "    \n",
        "\n",
        "    prob_pred_X = predict_one_sample(model_ft, X)\n",
        "    prob_pred_x = predict_one_sample(model_ft, x.cuda())\n",
        "\n",
        "    predicted_proba_X = np.max(prob_pred_X)*100\n",
        "    predicted_proba_x = np.max(prob_pred_x)*100\n",
        "\n",
        "    y_pred_X = np.argmax(prob_pred_X)\n",
        "    y_pred_x = np.argmax(prob_pred_x)\n",
        "\n",
        "    predicted_label_X = label_encoder.classes_[y_pred_X]\n",
        "    predicted_label_x = label_encoder.classes_[y_pred_x]\n",
        "\n",
        "    if plot:\n",
        "        fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
        "        ax.imshow(pic_np)\n",
        "        ax.set_title('True: ' + label_encoder.classes_[y] + ' ; Predicted: ' + predicted_label_x + ' ; Fake: ' + predicted_label_X, fontsize = 14)\n",
        "\n",
        "    return predicted_label_x, predicted_label_X, y, t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdMBumjPfd8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we should push decision of our classifier toward to t with adversary - let's do it and check\n",
        "\n",
        "eps = 0.1\n",
        "num_steps = 50\n",
        "step_size = 0.01\n",
        "\n",
        "predicted_label_x, predicted_label_X, y, t = test_adversarial(model_ft, eps, num_steps, step_size, plot=True)\n",
        "print('Compare: this one ', predicted_label_X, ' should match ' ,label_encoder.classes_[t]) # matched"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e0rbOZ6XpqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eps_list = [0.05 + i*0.01 for i in range(20)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buxyCufPU0P0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# small 1D gridsearch near the good starting epsilon to check whether prediction is really shifted towards new class t after attack\n",
        "\n",
        "predicted_label_x_list = []\n",
        "predicted_label_X_list = []\n",
        "y_list = []\n",
        "t_list = []\n",
        "\n",
        "ratio_predicted_advers_to_t = []\n",
        "ratio_predicted_x_to_X = []\n",
        "ratio_misclass = []\n",
        "\n",
        "Num = 10\n",
        "\n",
        "#eps = 0.01\n",
        "num_steps = 50\n",
        "step_size = 0.01\n",
        "\n",
        "\n",
        "for eps in tqdm(eps_list):\n",
        "\n",
        "    N_pred_x_to_X = 0\n",
        "    N_x_adv_to_t = 0\n",
        "    N_misclass = 0\n",
        "\n",
        "    for _ in range(Num):\n",
        "\n",
        "        predicted_label_x, predicted_label_X, y, t = test_adversarial(model_ft, eps, num_steps, step_size, plot=False)\n",
        "\n",
        "        if (predicted_label_X == label_encoder.classes_[t]): N_x_adv_to_t += 1 # should be close to 1\n",
        "        if (predicted_label_X == predicted_label_x): N_pred_x_to_X += 1 # should decrease with increasing eps\n",
        "        if (predicted_label_x != label_encoder.classes_[y]): N_misclass += 1 # should be zero\n",
        "        #predicted_label_x_list.append(predicted_label_x)\n",
        "        #predicted_label_X_list.append(predicted_label_X)\n",
        "        #y_list.append(y)\n",
        "        #t_list.append(t)\n",
        "\n",
        "    ratio_predicted_advers_to_t.append(N_x_adv_to_t/Num)\n",
        "    ratio_predicted_x_to_X.append(N_pred_x_to_X/Num)\n",
        "    ratio_misclass.append(N_misclass/Num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNLZz3Zaatgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (30, 10))\n",
        "\n",
        "ax1.plot(eps_list, ratio_predicted_advers_to_t)\n",
        "ax2.plot(eps_list, ratio_predicted_x_to_X)\n",
        "ax3.plot(eps_list, ratio_misclass)\n",
        "\n",
        "ax1.set_title('Ratio of predicted from adv examples to gen t', fontsize = 16)\n",
        "ax2.set_title('Ratio of predicted from adv examples to true inputs', fontsize = 16)\n",
        "ax3.set_title('Ratio of misclassified images', fontsize = 16)\n",
        "\n",
        "ax1.set_xlabel(r'$\\varepsilon$', fontsize = 18)\n",
        "ax2.set_xlabel(r'$\\varepsilon$', fontsize = 18)\n",
        "ax3.set_xlabel(r'$\\varepsilon$', fontsize = 18)\n",
        "\n",
        "ax1.set_ylabel('ratio', fontsize = 18)\n",
        "ax2.set_ylabel('ratio', fontsize = 18)\n",
        "ax3.set_ylabel('ratio', fontsize = 18)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDvqg8i2oLx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset_item(model_ft, rand_idx, eps=0.01, num_steps=10, step_size=0.01):\n",
        "    attack = LinfPGDAttack(model_ft, eps, num_steps, step_size)\n",
        "    labels = list(range(1, 43))\n",
        "\n",
        "    #rand_idx = np.random.randint(len(image_datasets['train']))\n",
        "    x, y = image_datasets['train'][rand_idx]\n",
        "\n",
        "    x=x.reshape(1,3,224,224)\n",
        "    X, t = attack.perturb(x, y, labels, model_ft)\n",
        "    pic_np = X.detach().cpu().numpy().reshape(3, 224,224)\n",
        "    #pic_np = np.rollaxis(pic_np, 0, 3)    # 3xHxW to HxWx3\n",
        "\n",
        "    return pic_np, t.item(), y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eal7ObR2iUh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate dataset based on adversarial examples from simpsons dataset with chosen parameters\n",
        "\n",
        "eps=0.15\n",
        "num_steps=50\n",
        "step_size=0.01\n",
        "\n",
        "#simp_NR = []\n",
        "dataset = image_datasets['val']\n",
        "\n",
        "#for i in tqdm(range(len(dataset))):\n",
        "for i in tqdm(range(1000, 1500)):\n",
        "\n",
        "    attack = LinfPGDAttack(model_ft, eps, num_steps, step_size)\n",
        "    labels = list(range(1, 43))\n",
        "\n",
        "    #x, y = image_datasets['train'][i]\n",
        "    x, y = dataset[i]\n",
        "    x=x.reshape(1,3,224,224)\n",
        "    X, t = attack.perturb(x, y, labels, model_ft)\n",
        "    pic = X.detach().cpu().numpy().reshape(3, 224,224)\n",
        "\n",
        "    simp_NR.append([pic, t.item(), y])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e52AsBW8xRsh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # save obtained dataset\n",
        "\n",
        "#torch.save(simp_NR, 'Simpsons_non_robust.pt') # - uncommnet this in case you want to save dataset "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lbPyldK0vq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adversarial_ds = torch.load('Simpsons_non_robust.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMOzzsZE5_qd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# without normalization\n",
        "\n",
        "def imshow2(inp, title=None, plt_ax=plt, default=False):\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    #mean = np.array([0.485, 0.456, 0.406])\n",
        "    #std = np.array([0.229, 0.224, 0.225])\n",
        "    #inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt_ax.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt_ax.set_title(title)\n",
        "    plt_ax.grid(False)\n",
        "    plt_ax.figure.savefig('simpsons_dataset.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrKOlZfFY_4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's validate obtained examples\n",
        "\n",
        "fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(12, 12), \\\n",
        "                        sharey=True, sharex=True)\n",
        "\n",
        "for fig_x in ax.flatten():\n",
        "    random_characters = int(np.random.uniform(0, 1500))\n",
        "    im_val, label_new, label_old = adversarial_ds[random_characters]\n",
        "\n",
        "    #img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
        "    #            adversarial_ds.label_encoder.inverse_transform([label])[0].split('_')))\n",
        "    im_val = torch.tensor(im_val)\n",
        "    imshow2(im_val.data, title='Original label: ' + label_encoder.classes_[label_old], plt_ax=fig_x)\n",
        "    \n",
        "    #actual_text = \"Shifted label : {}\".format(label_encoder.classes_[label_new])\n",
        "\n",
        "    fig_x.add_patch(patches.Rectangle((0, 53), 86, 35, color='white'))\n",
        "    font0 = FontProperties()\n",
        "    font = font0.copy()\n",
        "    font.set_family(\"fantasy\")\n",
        "    prob_pred = predict_one_sample(model_ft, im_val.unsqueeze(0))\n",
        "    predicted_proba = np.max(prob_pred)*100\n",
        "    y_pred = np.argmax(prob_pred)\n",
        "    \n",
        "    predicted_label = label_encoder.classes_[y_pred]\n",
        "    predicted_label = predicted_label[:len(predicted_label)//2] + '\\n' + predicted_label[len(predicted_label)//2:]\n",
        "    predicted_text = \"{} : {:.0f}%\".format(predicted_label,predicted_proba)\n",
        "            \n",
        "    fig_x.text(1, 59, predicted_text , horizontalalignment='left', fontproperties=font,\n",
        "                    verticalalignment='top',fontsize=8, color='black',fontweight='bold')\n",
        "    \n",
        "plt.savefig('simpson_predict.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMPWq_sNuuIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install einops\n",
        "\n",
        "import utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MD_FkIWBq3Kc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from utils import compute_loss, compute_accuracy, plot_loss_and_accuracy, plot_classes_preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw-SVGxBwX6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 10\n",
        "dataloader_adv = torch.utils.data.DataLoader(adversarial_ds, batch_size=batch_size, shuffle=False, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myLVYVXVvTb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_accuracy_batch_t = []\n",
        "val_accuracy_batch_y = []\n",
        "\n",
        "for X_batch, t_batch, y_batch in tqdm(dataloader_adv):\n",
        "    # transferring batch to GPU\n",
        "    X_batch = torch.tensor(X_batch)\n",
        "    X_batch_gpu = X_batch.to(device)\n",
        "    # forward propagation through the model\n",
        "    logits = model_ft(X_batch_gpu)\n",
        "\n",
        "    # let's calculate the accuracy:\n",
        "    accuracy1 = compute_accuracy(logits, t_batch, device=device)\n",
        "    accuracy2 = compute_accuracy(logits, y_batch, device=device)\n",
        "\n",
        "    val_accuracy_batch_t.append(accuracy1.item())\n",
        "    val_accuracy_batch_y.append(accuracy2.item())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8x8GKTvdvlWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Accuracy on adverasarial dataset (for generated labels): {} %'.format(accuracy1.cpu().numpy() * 100))\n",
        "print('Accuracy on adverasarial dataset (for original labels): {} %'.format(accuracy2.cpu().numpy() * 100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBKdZYns8opi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lets validate on unused pictures - from train (test pictures are unlabeled)\n",
        "\n",
        "subset_indices = [i for i in range(500)] # select your indices here as a list\n",
        "subset = torch.utils.data.Subset(image_datasets['train'], subset_indices)\n",
        "testloader = torch.utils.data.DataLoader(subset, batch_size=1, num_workers=0, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqoKJ6HxwyIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython import display\n",
        "\n",
        "def run(net, train_loader, \n",
        "        path_save_dict='./drive/My Drive/Project_DL/checkpoint_renet_50_robust.pth',\n",
        "        n_epoch=50, lr=0.1, momentum=0.9, scheduled=False):\n",
        "  \n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
        "  net.to(device)\n",
        "\n",
        "  if len(net) == 2:\n",
        "    # if resnet\n",
        "    criterion = nn.CrossEntropyLoss() \n",
        "  else:\n",
        "    # if vgg \n",
        "    criterion = nn.NLLLoss()\n",
        "    \n",
        "  # optimizer = optim.Adam(net.parameters(), lr=0.01, weight_decay=5*1e-4)\n",
        "  optimizer = torch.optim.SGD(net.parameters(), lr=lr, \n",
        "                              momentum=momentum, weight_decay=5*1e-4)\n",
        "  if scheduled:\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, \n",
        "                                                step_size=15, gamma=0.1)\n",
        "\n",
        "  test_accuracy = []\n",
        "  train_accuracy = []\n",
        "\n",
        "  loss_train = []\n",
        "  best_accuracy = 10\n",
        "  for epoch in tqdm(range(n_epoch)):  # loop over the dataset multiple times\n",
        "\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      net.train()\n",
        "      running_loss = []\n",
        "      for i, data in enumerate(train_loader):\n",
        "          \n",
        "          # get the inputs; data is a list of [inputs, labels]\n",
        "          inputs, labels, _ = data\n",
        "\n",
        "          inputs = torch.tensor(inputs)\n",
        "          labels = torch.tensor(labels)\n",
        "\n",
        "          inputs_gpu = inputs.to(device)\n",
        "          labels_gpu = labels.to(device)\n",
        "\n",
        "          # zero the parameter gradients\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # forward + backward + optimize\n",
        "\n",
        "          # comment if using our net\n",
        "          if len(net) == 2:\n",
        "            outputs = net[1](net[0](inputs_gpu))\n",
        "          else:\n",
        "          # comment if using resnet\n",
        "            outputs = net(inputs_gpu)\n",
        "\n",
        "          loss = criterion(outputs, labels_gpu)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # print statistics\n",
        "          running_loss.append(loss.item())\n",
        "\n",
        "          # evaluate train accuracy\n",
        "          with torch.no_grad():\n",
        "            #_, predicted = torch.max(nn.Softmax()(outputs).data, 1)\n",
        "\n",
        "            predicted = nn.functional.softmax(outputs, dim=1).detach().argmax(dim=1)\n",
        "            total += labels_gpu.size(0)\n",
        "            correct += (predicted == labels_gpu).sum().item()\n",
        "\n",
        "      loss_train.append(np.mean(running_loss))\n",
        "      train_accuracy.append(100 * correct / total)\n",
        "\n",
        "      # evaluate on test dataloader\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      net.eval()\n",
        "      with torch.no_grad():\n",
        "          for data in testloader:\n",
        "              images, labels = data\n",
        "              images = images.to(device)\n",
        "              labels = labels.to(device)\n",
        "\n",
        "              # comment if using our net\n",
        "              if len(net) == 2:\n",
        "                outputs = net[1](net[0](images))\n",
        "              else:\n",
        "                # comment if using resnet\n",
        "                outputs = net(images)\n",
        "              \n",
        "              #_, predicted = torch.max(nn.Softmax()(outputs).data, 1)\n",
        "              predicted = nn.functional.softmax(outputs, dim=1).detach().argmax(dim=1)\n",
        "              total += labels.size(0)\n",
        "              correct += (predicted == labels).sum().item()\n",
        "\n",
        "      test_accuracy.append(100 * correct / total)\n",
        "      \n",
        "      if len(train_accuracy) > 2 and train_accuracy[-1] > best_accuracy:\n",
        "        torch.save(net.state_dict(), path_save_dict)\n",
        "        best_accuracy = test_accuracy[-1] \n",
        "\n",
        "      display.clear_output(True)\n",
        "      plt.figure(figsize=(16, 8))\n",
        "      plt.subplot(121)\n",
        "      plt.plot(loss_train, label='train loss')\n",
        "      plt.xlabel('Epoch')\n",
        "      plt.ylabel('Loss') \n",
        "\n",
        "      plt.subplot(122)\n",
        "      plt.plot(train_accuracy, label='train accuracy')   \n",
        "      plt.plot(test_accuracy, label='test accuracy')\n",
        "      plt.xlabel('Iterations')\n",
        "      plt.ylabel('Accuracy')\n",
        "\n",
        "      plt.show() \n",
        "      print('#Epoch: %d | Loss Train: %.3f | Acc train: %.3f | Acc: %.3f' % \n",
        "            (epoch, loss_train[-1], train_accuracy[-1], test_accuracy[-1]))\n",
        "      \n",
        "      if scheduled:\n",
        "        # Decay Learning Rate\n",
        "        scheduler.step()\n",
        "      \n",
        "  print('Finished Training')\n",
        "  return net, test_accuracy, loss_train, train_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXlsA98pyURw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet50 = torchvision.models.resnet50(pretrained=True,progress=True)\n",
        "net = nn.ModuleList([resnet50, nn.Linear(1000, 42)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkOerMe_2iWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net, test_accuracy_drand, train_loss_drand, train_accuracy_drand = run(net, \n",
        "                                                                       train_loader = dataloader_adv, \n",
        "                                                                       path_save_dict='checkpoint_resnet_50_drand_sympsons.pth',\n",
        "                                                                       n_epoch=120, \n",
        "                                                                       lr=0.01, \n",
        "                                                                       scheduled=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hpd3led8AUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}